2025-12-22 15:21:41 - MainPipeline - INFO - Configuration loaded from configs/ingestion_config.yaml
2025-12-22 15:21:41 - MainPipeline - INFO - --- STAGE: DATA INGESTION ---
2025-12-22 15:21:41 - IngestionOrchestrator - INFO - Starting Direct ETL Ingestion...
2025-12-22 15:21:41 - IngestionOrchestrator - INFO - Extract-Transform-Load process for train -> fact_energy_usage
2025-12-22 15:21:41 - CSVIngestor - INFO - Starting chunked read for ./Raw_Data/train.csv
2025-12-22 15:21:43 - CSVIngestor - INFO - Processed batch 1 (200000 rows)...
2025-12-22 15:21:50 - CSVIngestor - INFO - Processed batch 6 (1200000 rows)...
2025-12-22 15:21:58 - CSVIngestor - INFO - Processed batch 11 (2200000 rows)...
2025-12-22 15:22:06 - CSVIngestor - INFO - Processed batch 16 (3200000 rows)...
2025-12-22 15:22:13 - CSVIngestor - INFO - Processed batch 21 (4200000 rows)...
2025-12-22 15:22:21 - CSVIngestor - INFO - Processed batch 26 (5200000 rows)...
2025-12-22 15:22:29 - CSVIngestor - INFO - Processed batch 31 (6200000 rows)...
2025-12-22 15:22:37 - CSVIngestor - INFO - Processed batch 36 (7200000 rows)...
2025-12-22 15:22:45 - CSVIngestor - INFO - Processed batch 41 (8200000 rows)...
2025-12-22 15:22:53 - CSVIngestor - INFO - Processed batch 46 (9200000 rows)...
2025-12-22 15:23:00 - CSVIngestor - INFO - Processed batch 51 (10200000 rows)...
2025-12-22 15:23:08 - CSVIngestor - INFO - Processed batch 56 (11200000 rows)...
2025-12-22 15:23:16 - CSVIngestor - INFO - Processed batch 61 (12200000 rows)...
2025-12-22 15:23:24 - CSVIngestor - INFO - Processed batch 66 (13200000 rows)...
2025-12-22 15:23:31 - CSVIngestor - INFO - Processed batch 71 (14200000 rows)...
2025-12-22 15:23:39 - CSVIngestor - INFO - Processed batch 76 (15200000 rows)...
2025-12-22 15:23:47 - CSVIngestor - INFO - Processed batch 81 (16200000 rows)...
2025-12-22 15:23:54 - CSVIngestor - INFO - Processed batch 86 (17200000 rows)...
2025-12-22 15:24:02 - CSVIngestor - INFO - Processed batch 91 (18200000 rows)...
2025-12-22 15:24:10 - CSVIngestor - INFO - Processed batch 96 (19200000 rows)...
2025-12-22 15:24:18 - CSVIngestor - INFO - Processed batch 101 (20200000 rows)...
2025-12-22 15:24:18 - IngestionOrchestrator - INFO - Extract-Transform-Load process for building -> dim_building
2025-12-22 15:24:18 - CSVIngestor - INFO - Starting chunked read for ./Raw_Data/building_metadata.csv
2025-12-22 15:24:18 - CSVIngestor - INFO - Processed batch 1 (200000 rows)...
2025-12-22 15:24:18 - IngestionOrchestrator - INFO - Extract-Transform-Load process for weather -> dim_weather
2025-12-22 15:24:18 - CSVIngestor - INFO - Starting chunked read for ./Raw_Data/weather_train.csv
2025-12-22 15:24:18 - DataTransformer - INFO - Transforming weather data: Performing site-based imputation...
2025-12-22 15:24:18 - DataTransformer - INFO - Weather transformation complete. 0 missing values for primary metrics.
2025-12-22 15:24:21 - CSVIngestor - INFO - Processed batch 1 (200000 rows)...
2025-12-22 15:24:21 - IngestionOrchestrator - INFO - --- INGESTION SUMMARY ---
2025-12-22 15:24:21 - IngestionOrchestrator - INFO - TABLE: TRAIN | ROWS: 20216100 | STATUS: SUCCESS
2025-12-22 15:24:21 - IngestionOrchestrator - INFO - TABLE: BUILDING | ROWS: 1449 | STATUS: SUCCESS
2025-12-22 15:24:21 - IngestionOrchestrator - INFO - TABLE: WEATHER | ROWS: 139773 | STATUS: SUCCESS
2025-12-22 15:24:21 - MainPipeline - INFO - Ingestion stage completed successfully.
2025-12-22 16:32:04 - MainPipeline - INFO - Configuration loaded from configs/ingestion_config.yaml
2025-12-22 16:32:04 - MainPipeline - INFO - --- STAGE: DATA INGESTION ---
2025-12-22 16:32:04 - IngestionOrchestrator - INFO - Starting Direct ETL Ingestion...
2025-12-22 16:32:04 - IngestionOrchestrator - INFO - Extract-Transform-Load process for train -> fact_energy_usage
2025-12-22 16:32:04 - CSVIngestor - INFO - Starting chunked read for ./Raw_Data/train.csv
2025-12-22 16:32:06 - CSVIngestor - INFO - Processed batch 1 (200000 rows)...
2025-12-22 16:32:16 - CSVIngestor - INFO - Processed batch 6 (1200000 rows)...
2025-12-22 16:32:26 - CSVIngestor - INFO - Processed batch 11 (2200000 rows)...
2025-12-22 16:32:36 - CSVIngestor - INFO - Processed batch 16 (3200000 rows)...
2025-12-22 16:32:47 - CSVIngestor - INFO - Processed batch 21 (4200000 rows)...
2025-12-22 16:32:59 - CSVIngestor - INFO - Processed batch 26 (5200000 rows)...
2025-12-22 16:33:12 - CSVIngestor - INFO - Processed batch 31 (6200000 rows)...
2025-12-22 16:33:23 - CSVIngestor - INFO - Processed batch 36 (7200000 rows)...
2025-12-22 16:33:34 - CSVIngestor - INFO - Processed batch 41 (8200000 rows)...
2025-12-22 16:33:44 - CSVIngestor - INFO - Processed batch 46 (9200000 rows)...
2025-12-22 16:33:55 - CSVIngestor - INFO - Processed batch 51 (10200000 rows)...
2025-12-22 16:34:06 - CSVIngestor - INFO - Processed batch 56 (11200000 rows)...
2025-12-22 16:34:16 - CSVIngestor - INFO - Processed batch 61 (12200000 rows)...
2025-12-22 16:34:27 - CSVIngestor - INFO - Processed batch 66 (13200000 rows)...
2025-12-22 16:34:37 - CSVIngestor - INFO - Processed batch 71 (14200000 rows)...
2025-12-22 16:34:48 - CSVIngestor - INFO - Processed batch 76 (15200000 rows)...
2025-12-22 16:34:58 - CSVIngestor - INFO - Processed batch 81 (16200000 rows)...
2025-12-22 16:35:09 - CSVIngestor - INFO - Processed batch 86 (17200000 rows)...
2025-12-22 16:35:19 - CSVIngestor - INFO - Processed batch 91 (18200000 rows)...
2025-12-22 16:35:30 - CSVIngestor - INFO - Processed batch 96 (19200000 rows)...
2025-12-22 16:35:40 - CSVIngestor - INFO - Processed batch 101 (20200000 rows)...
2025-12-22 16:35:40 - IngestionOrchestrator - INFO - Extract-Transform-Load process for building -> dim_building
2025-12-22 16:35:40 - CSVIngestor - INFO - Starting chunked read for ./Raw_Data/building_metadata.csv
2025-12-22 16:35:40 - CSVIngestor - INFO - Processed batch 1 (200000 rows)...
2025-12-22 16:35:40 - IngestionOrchestrator - INFO - Extract-Transform-Load process for weather -> dim_weather
2025-12-22 16:35:40 - CSVIngestor - INFO - Starting chunked read for ./Raw_Data/weather_train.csv
2025-12-22 16:35:40 - DataTransformer - INFO - Transforming weather data: Imputing missing values...
2025-12-22 16:35:44 - CSVIngestor - INFO - Processed batch 1 (200000 rows)...
2025-12-22 16:35:44 - IngestionOrchestrator - INFO - --- INGESTION SUMMARY ---
2025-12-22 16:35:44 - IngestionOrchestrator - INFO - TABLE: TRAIN | ROWS: 20216100 | STATUS: SUCCESS
2025-12-22 16:35:44 - IngestionOrchestrator - INFO - TABLE: BUILDING | ROWS: 1449 | STATUS: SUCCESS
2025-12-22 16:35:44 - IngestionOrchestrator - INFO - TABLE: WEATHER | ROWS: 139773 | STATUS: SUCCESS
2025-12-22 16:35:44 - MainPipeline - INFO - Ingestion stage completed successfully.
2025-12-24 10:06:54 - MainPipeline - INFO - Configuration loaded from /home/bishesh/mlops/configs/ingestion_config.yaml
2025-12-24 10:06:54 - MainPipeline - INFO - --- STAGE: DATA INGESTION ---
2025-12-24 10:06:54 - IngestionOrchestrator - INFO - Starting Direct ETL Ingestion...
2025-12-24 10:06:54 - IngestionOrchestrator - INFO - Extract-Transform-Load process for train -> fact_energy_usage
2025-12-24 10:06:54 - CSVIngestor - INFO - Starting chunked read for ./Raw_Data/train.csv
2025-12-24 10:06:54 - MainPipeline - CRITICAL - Pipeline failed at stage [ingestion]: (pymysql.err.OperationalError) (2003, "Can't connect to MySQL server on 'localhost' ([Errno 111] Connection refused)")
(Background on this error at: https://sqlalche.me/e/20/e3q8)
Traceback (most recent call last):
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/pymysql/connections.py", line 661, in connect
    sock = socket.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/socket.py", line 863, in create_connection
    raise exceptions[0]
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/socket.py", line 848, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 143, in __init__
    self._dbapi_connection = engine.raw_connection()
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 3309, in raw_connection
    return self.pool.connect()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 447, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 1264, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 711, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    with util.safe_reraise():
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/impl.py", line 175, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 388, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 673, in __init__
    self.__connect()
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 899, in __connect
    with util.safe_reraise():
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 895, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/engine/create.py", line 661, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 630, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/pymysql/connections.py", line 365, in __init__
    self.connect()
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/pymysql/connections.py", line 723, in connect
    raise exc
pymysql.err.OperationalError: (2003, "Can't connect to MySQL server on 'localhost' ([Errno 111] Connection refused)")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/bishesh/mlops/main.py", line 58, in main
    metrics = run_ingestion_stage(config)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/mlops/src/ingestion/orchestrator.py", line 58, in run_ingestion_stage
    return stage.run()
           ^^^^^^^^^^^
  File "/home/bishesh/mlops/src/ingestion/orchestrator.py", line 24, in run
    metrics = self._ingest_file(file_info)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/mlops/src/ingestion/orchestrator.py", line 43, in _ingest_file
    self.writer.write_chunk(clean_chunk, table, is_first_chunk=is_first)
  File "/home/bishesh/mlops/src/ingestion/db_writer.py", line 24, in write_chunk
    with self.engine.connect() as conn:
         ^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 3285, in connect
    return self._connection_cls(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2448, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 143, in __init__
    self._dbapi_connection = engine.raw_connection()
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 3309, in raw_connection
    return self.pool.connect()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 447, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 1264, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 711, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    with util.safe_reraise():
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/impl.py", line 175, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 388, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 673, in __init__
    self.__connect()
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 899, in __connect
    with util.safe_reraise():
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 895, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/engine/create.py", line 661, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 630, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/pymysql/connections.py", line 365, in __init__
    self.connect()
  File "/home/bishesh/miniconda3/envs/myenv/lib/python3.11/site-packages/pymysql/connections.py", line 723, in connect
    raise exc
sqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (2003, "Can't connect to MySQL server on 'localhost' ([Errno 111] Connection refused)")
(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-12-24 10:09:56 - MainPipeline - INFO - Configuration loaded from /home/bishesh/mlops/configs/ingestion_config.yaml
2025-12-24 10:09:56 - MainPipeline - INFO - --- STAGE: DATA INGESTION ---
2025-12-24 10:09:56 - IngestionOrchestrator - INFO - Starting Direct ETL Ingestion...
2025-12-24 10:09:56 - IngestionOrchestrator - INFO - Extract-Transform-Load process for train -> fact_energy_usage
2025-12-24 10:09:56 - CSVIngestor - INFO - Starting chunked read for ./Raw_Data/train.csv
2025-12-24 10:10:00 - CSVIngestor - INFO - Processed batch 1 (200000 rows)...
2025-12-24 10:10:17 - CSVIngestor - INFO - Processed batch 6 (1200000 rows)...
2025-12-24 10:10:32 - CSVIngestor - INFO - Processed batch 11 (2200000 rows)...
2025-12-24 10:10:46 - CSVIngestor - INFO - Processed batch 16 (3200000 rows)...
2025-12-24 10:11:01 - CSVIngestor - INFO - Processed batch 21 (4200000 rows)...
2025-12-24 10:11:15 - CSVIngestor - INFO - Processed batch 26 (5200000 rows)...
2025-12-24 10:11:30 - CSVIngestor - INFO - Processed batch 31 (6200000 rows)...
2025-12-24 10:11:45 - CSVIngestor - INFO - Processed batch 36 (7200000 rows)...
2025-12-24 10:11:59 - CSVIngestor - INFO - Processed batch 41 (8200000 rows)...
2025-12-24 10:12:16 - CSVIngestor - INFO - Processed batch 46 (9200000 rows)...
2025-12-24 10:12:43 - CSVIngestor - INFO - Processed batch 51 (10200000 rows)...
2025-12-24 10:13:07 - CSVIngestor - INFO - Processed batch 56 (11200000 rows)...
2025-12-24 10:13:30 - CSVIngestor - INFO - Processed batch 61 (12200000 rows)...
2025-12-24 10:13:52 - CSVIngestor - INFO - Processed batch 66 (13200000 rows)...
2025-12-24 10:14:16 - CSVIngestor - INFO - Processed batch 71 (14200000 rows)...
2025-12-24 10:14:39 - CSVIngestor - INFO - Processed batch 76 (15200000 rows)...
2025-12-24 10:15:01 - CSVIngestor - INFO - Processed batch 81 (16200000 rows)...
2025-12-24 10:15:24 - CSVIngestor - INFO - Processed batch 86 (17200000 rows)...
2025-12-24 10:15:48 - CSVIngestor - INFO - Processed batch 91 (18200000 rows)...
2025-12-24 10:16:10 - CSVIngestor - INFO - Processed batch 96 (19200000 rows)...
2025-12-24 10:16:31 - CSVIngestor - INFO - Processed batch 101 (20200000 rows)...
2025-12-24 10:16:31 - IngestionOrchestrator - INFO - Extract-Transform-Load process for building -> dim_building
2025-12-24 10:16:31 - CSVIngestor - INFO - Starting chunked read for ./Raw_Data/building_metadata.csv
2025-12-24 10:16:31 - CSVIngestor - INFO - Processed batch 1 (200000 rows)...
2025-12-24 10:16:31 - IngestionOrchestrator - INFO - Extract-Transform-Load process for weather -> dim_weather
2025-12-24 10:16:31 - CSVIngestor - INFO - Starting chunked read for ./Raw_Data/weather_train.csv
2025-12-24 10:16:31 - DataTransformer - INFO - Transforming weather data: Imputing missing values...
2025-12-24 10:16:45 - CSVIngestor - INFO - Processed batch 1 (200000 rows)...
2025-12-24 10:16:45 - IngestionOrchestrator - INFO - --- INGESTION SUMMARY ---
2025-12-24 10:16:45 - IngestionOrchestrator - INFO - TABLE: TRAIN | ROWS: 20216100 | STATUS: SUCCESS
2025-12-24 10:16:45 - IngestionOrchestrator - INFO - TABLE: BUILDING | ROWS: 1449 | STATUS: SUCCESS
2025-12-24 10:16:45 - IngestionOrchestrator - INFO - TABLE: WEATHER | ROWS: 139773 | STATUS: SUCCESS
2025-12-24 10:16:45 - MainPipeline - INFO - Ingestion stage completed successfully.
